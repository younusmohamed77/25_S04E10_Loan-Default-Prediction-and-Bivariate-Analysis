{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac3baac-d4e9-4d05-b8d3-282d547c3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9acd3c82-f290-4f7d-ab66-feb2555c5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac086add-09d6-4c9a-bfc4-7efb37c6985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "cpus = len(tf.config.list_physical_devices('CPU'))\n",
    "\n",
    "print(gpus, cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afff1aea-3f67-456f-a727-09563df92a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>B</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>N</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>OWN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0   0          37          35000                  RENT                0.0   \n",
       "1   1          22          56000                   OWN                6.0   \n",
       "\n",
       "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "0   EDUCATION          B       6000          11.49                 0.17   \n",
       "1     MEDICAL          C       4000          13.35                 0.07   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  \n",
       "0                         N                          14            0  \n",
       "1                         N                           2            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1b4128-a05a-4f92-b037-51f27327c111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58645</td>\n",
       "      <td>23</td>\n",
       "      <td>69000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>HOMEIMPROVEMENT</td>\n",
       "      <td>F</td>\n",
       "      <td>25000</td>\n",
       "      <td>15.76</td>\n",
       "      <td>0.36</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58646</td>\n",
       "      <td>26</td>\n",
       "      <td>96000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>6.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>C</td>\n",
       "      <td>10000</td>\n",
       "      <td>12.68</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0  58645          23          69000                  RENT                3.0   \n",
       "1  58646          26          96000              MORTGAGE                6.0   \n",
       "\n",
       "       loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
       "0  HOMEIMPROVEMENT          F      25000          15.76                 0.36   \n",
       "1         PERSONAL          C      10000          12.68                 0.10   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "0                         N                           2  \n",
       "1                         Y                           4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d50cdd-d4a4-433e-a1a9-4cb29ac4e900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['loan_status'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7138fb6-de90-4fb7-ac4a-a4389f173f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20241007_135639\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.8.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       24.82 GB / 31.82 GB (78.0%)\n",
      "Disk Space Avail:   663.25 GB / 953.00 GB (69.6%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 9900s of the 39600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-10-07 17:56:42,021\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\t\tContext path: \"AutogluonModels\\ag-20241007_135639\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Beginning AutoGluon training ... Time limit = 9895s\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m AutoGluon will save models to \"AutogluonModels\\ag-20241007_135639\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Train Data Rows:    52128\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Train Data Columns: 12\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Label Column:       loan_status\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tAvailable Memory:                    24163.02 MB\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tTrain Data (Original)  Memory Usage: 15.39 MB (0.1% of available memory)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t('float', [])  : 3 | ['person_emp_length', 'loan_int_rate', 'loan_percent_income']\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t('int', [])    : 5 | ['id', 'person_age', 'person_income', 'loan_amnt', 'cb_person_cred_hist_length']\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t('object', []) : 4 | ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t('category', [])  : 3 | ['person_home_ownership', 'loan_intent', 'loan_grade']\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t('float', [])     : 3 | ['person_emp_length', 'loan_int_rate', 'loan_percent_income']\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t('int', [])       : 5 | ['id', 'person_age', 'person_income', 'loan_amnt', 'cb_person_cred_hist_length']\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t('int', ['bool']) : 1 | ['cb_person_default_on_file']\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t12 features in original data used to generate 12 features in processed data.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tTrain Data (Processed) Memory Usage: 3.38 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting 108 L1 models ...\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 6595.24s of the 9895.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.11%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=19140)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.172249\n",
      "\u001b[36m(_ray_fit pid=20796)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.163123\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9391\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t13.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.43s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 6577.75s of the 9877.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9567\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t8.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 6567.78s of the 9867.87s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9349\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t2.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t1.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 6564.42s of the 9864.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.936\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t1.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t1.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 6561.26s of the 9861.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9549\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t310.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 6248.84s of the 9548.92s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9233\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t1.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 6246.42s of the 9546.5s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9236\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.94s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t1.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 6244.04s of the 9544.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=13460, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=13460, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\common\\utils\\try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 6242.38s of the 9542.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9538\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t10.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 6230.05s of the 9530.14s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=7832)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=7832)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=6956)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6956)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=10856)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=10856)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=15888)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=15888)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=18852)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=18852)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=14468)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=14468)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=23232)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=23232)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9295\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t196.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.21s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 6032.2s of the 9332.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_ray_fit pid=23404)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=23404)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9554\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t11.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 6018.67s of the 9318.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9554\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t37.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 5979.74s of the 9279.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=21960)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=21960)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=15264)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=15264)\u001b[0m   self.model = torch.load(net_filename)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10404)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=10404)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=23436)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=23436)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2536)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2536)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=6104)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6104)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9314\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t343.52s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 5634.53s of the 8934.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.12%)\n",
      "\u001b[36m(_ray_fit pid=22520)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=22520)\u001b[0m   self.model = torch.load(net_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=9708)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.134689\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19864)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.150931\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=20260)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.145277\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9581\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t16.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.65s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 5616.01s of the 8916.1s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tWarning: Exception caused NeuralNetFastAI_r191_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21852, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=21852, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\common\\utils\\try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 5614.37s of the 8914.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9555\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t140.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 5471.81s of the 8771.9s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.11%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=18232)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.165331\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=18232)\u001b[0m [6000]\tvalid_set's binary_logloss: 0.152046\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=4396)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.178615\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=16092)\u001b[0m [5000]\tvalid_set's binary_logloss: 0.166655\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=16092)\u001b[0m [10000]\tvalid_set's binary_logloss: 0.164911\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=9880)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.167208\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=10284)\u001b[0m [8000]\tvalid_set's binary_logloss: 0.174192\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=14212)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.170612\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=14212)\u001b[0m [7000]\tvalid_set's binary_logloss: 0.162684\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=12972)\u001b[0m [8000]\tvalid_set's binary_logloss: 0.164619\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9418\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t54.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t4.6s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 5414.85s of the 8714.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.09%)\n",
      "\u001b[36m(_ray_fit pid=6668)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=6668)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2464)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2464)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=16636)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=16636)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=22044)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=22044)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=7808)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=7808)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=20768)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=20768)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=19500)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=19500)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=22040)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=22040)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9298\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t307.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 5105.95s of the 8406.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.28%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9536\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t22.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.47s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 5081.91s of the 8382.0s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9251\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t1.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t1.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 5079.42s of the 8379.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.11%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9571\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t528.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 4549.77s of the 7849.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tWarning: Exception caused NeuralNetFastAI_r102_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22660, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=22660, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\common\\utils\\try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 4548.13s of the 7848.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9536\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t120.22s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 4426.28s of the 7726.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.938\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t4.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.98s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 4420.17s of the 7720.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.14%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9347\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t14.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.42s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 4403.91s of the 7704.0s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.17%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tWarning: Exception caused NeuralNetFastAI_r145_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=10060, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m ModuleNotFoundError: No module named 'fastai'\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \u001b[36mray::_ray_fit()\u001b[39m (pid=10060, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1984, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1889, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py\", line 213, in _fit\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     try_import_fastai()\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m   File \"C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\common\\utils\\try_import.py\", line 122, in try_import_fastai\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m     raise ImportError(f\"Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]=={__version__}`. \")\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m ImportError: Import fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.1.1`.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 4402.25s of the 7702.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.15%)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.9552\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t14.15s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \t0.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 4386.46s of the 7686.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=5564)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=0.10%)\n",
      "\u001b[36m(_ray_fit pid=23532)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=23532)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=15560)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=15560)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=18604)\u001b[0m C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=18604)\u001b[0m   self.model = torch.load(net_filename)\n"
     ]
    }
   ],
   "source": [
    "# Train the AutoGluon TabularPredictor\n",
    "# Set up the TabularPredictor with GPU and memory optimization\n",
    "predictor = TabularPredictor(\n",
    "    label='loan_status',\n",
    "    eval_metric='roc_auc',\n",
    "    problem_type='binary'\n",
    ").fit(\n",
    "    train_df,\n",
    "    presets='best_quality',\n",
    "    time_limit=3600 * 11,\n",
    "    verbosity=2,\n",
    "    excluded_model_types=['KNN'],\n",
    "    ag_args_fit={'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}\n",
    ")\n",
    "\n",
    "# Summarize results\n",
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e324eb4d-1275-441d-bbb2-78dfcb4541b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20965900-c764-4e13-90e0-5d89f0f29045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the leaderboard to see the performance of the models\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "\n",
    "# Print the leaderboard for reference\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86eaac-c020-43d4-a5c9-712693fdb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 models based on the leaderboard\n",
    "top_10_models = leaderboard['model'].head(10).tolist()\n",
    "top_10_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafef6aa-c966-4247-8eb5-fa925aa75025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the top 10 models and print their hyperparameters\n",
    "for model in top_10_models:\n",
    "    hyperparameters = predictor.info()['model_info'][model]['hyperparameters']\n",
    "    print(f\"Model: {model}\")\n",
    "    print(\"Hyperparameters:\")\n",
    "    print(hyperparameters)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474d0ec-c5dc-46a8-bc25-91d7c6bc6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get details of the best model\n",
    "best_model = predictor.get_model_best()\n",
    "print(f\"Best Model: {best_model}\")\n",
    "\n",
    "# Get model hyperparameters and other info\n",
    "best_model_info = predictor.info()\n",
    "print(best_model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35aed2-05e7-4252-8ac5-e0c007e3cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = predictor.feature_importance(train_df)\n",
    "print(\"Feature Importance:\\n\", feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b537b-16d4-44e0-8dd5-dd02253787eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"sample_submission.csv\")\n",
    "sample_submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ff7a5-b6d9-4fb3-b5be-a67be8e203ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_predictor = predictor.predict(test_df)\n",
    "\n",
    "# Create the submission file\n",
    "sample_submission_df['loan_status'] = y_pred_predictor\n",
    "sample_submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f508ef-6429-4967-a0f8-cefa05f22e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df.to_csv('25_01 - Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ff8a2-a63a-47d6-a716-d42f98914dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
